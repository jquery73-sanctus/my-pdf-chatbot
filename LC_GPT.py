import streamlit as st
import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
# ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ê²½ë¡œë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì§€ì •
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain_community.callbacks import get_openai_callback

# 1. GUI í™”ë©´ ì„¤ì •
st.set_page_config(page_title="PDF ê°€ì´ë“œ ì±—ë´‡", layout="wide")
st.title("ğŸ“„ PDFì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” (í† í° ì¶”ì  í¬í•¨)")

# ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ê°’ ì…ë ¥ ë°›ê¸°
with st.sidebar:
    st.header("ì„¤ì •")
    openai_key = st.text_input("OpenAI API Key", type="password")
    st.info("API Keyë¥¼ ì…ë ¥í•˜ê³  PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤.")

# 2. PDF ì—…ë¡œë“œ ë° ì²˜ë¦¬ ë¡œì§
uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì±„íŒ… ê¸°ë¡ ì €ì¥ìš©)
if "messages" not in st.session_state:
    st.session_state.messages = []

if uploaded_file and openai_key:
    # ì„ì‹œ íŒŒì¼ ì €ì¥ (PyPDFLoaderëŠ” íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•¨)
    with open("temp.pdf", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # [ê³¼ì • 1] ë¬¸ì„œ ë¡œë“œ ë° ìª¼ê°œê¸°
    loader = PyPDFLoader("temp.pdf")
    data = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = text_splitter.split_documents(data)
    
    # [ê³¼ì • 2] ë²¡í„° ì €ì¥ì†Œ ë§Œë“¤ê¸° (FAISS)
    embeddings = OpenAIEmbeddings(openai_api_key=openai_key)
    vectorstore = FAISS.from_documents(chunks, embeddings)
    
    # [ê³¼ì • 3] ë­ì²´ì¸ ì—°ê²° (QA Chain)
    llm = ChatOpenAI(model_name="gpt-4o-mini", openai_api_key=openai_key, temperature=0)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever()
    )

    st.success("âœ… PDF ë¶„ì„ ì™„ë£Œ! ì´ì œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

    # 3. ì±„íŒ… UI í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input("ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ë‹µë³€ ìƒì„± ë° í† í° ì¶”ì 
        with st.chat_message("assistant"):
            with get_openai_callback() as cb:
                # ìµœì‹  ê¶Œì¥ ë°©ì‹ì¸ invoke ì‚¬ìš©
                result = qa_chain.invoke(prompt)
                response = result['result'] # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì—ì„œ ë‹µë³€ë§Œ ì¶”ì¶œ
                
                st.markdown(response)
                
                # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ì •ë³´ ì¶œë ¥
                st.info(f"""
                **ğŸ’° ì´ë²ˆ ì§ˆë¬¸ì˜ ë¹„ìš© ì˜ìˆ˜ì¦:**
                - ì‚¬ìš©ëœ ì´ í† í°: {cb.total_tokens}
                - ìƒì„¸: (ì…ë ¥ {cb.prompt_tokens} / ì¶œë ¥ {cb.completion_tokens})
                - ì˜ˆìƒ ë¹„ìš©: ${cb.total_cost:.5f} (ì•½ {cb.total_cost * 1400:.2f}ì›)
                """)
                
                st.session_state.messages.append({"role": "assistant", "content": response})

elif not openai_key:
    st.warning("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
